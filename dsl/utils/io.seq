from internal.gc import sizeof
from param import int_t

from ..types.shared_tensor import SharedTensor


def write_vector[TP](f: File, vector):
    _C.fwrite(vector.arr.ptr.as_byte(), sizeof[TP](), vector.elem_count(), f.fp)
    f._errcheck("error in write")


def write_matrix[TP](f: File, mat):
    for row in mat: write_vector[TP](f, row)


def read_vector[TP](f: File, length: int, binary: bool) -> list[TP]:
    if binary:
        arr = Array[TP](length)
        for i in range(length): arr[i] = ptr[TP](f.read(sizeof[TP]()).ptr.as_byte())[0]
        return list[TP](arr, length)
    return [TP(e.strip()) for e in next(f).split()[:length]]


def read_matrix[TP](f: File, rows: int, cols: int, binary: bool) -> list[list[TP]]:
    return [read_vector[TP](f, cols, binary) for _ in range(rows)]


def read_beaver_vector(mpc, f, f_mask, length, modulus, binary: bool):
    x_r = read_vector[typeof(modulus)](f, length, binary)
    r = read_vector[typeof(modulus)](f_mask, length, binary)
    share = x_r.add_mod(r, modulus) if mpc.pid == 2 else r

    return SharedTensor[list[typeof(modulus)]](
        share, x_r, r, modulus, x_r.zeros(),
        x_r.zeros(), False, False, False)


def read_beaver_matrix(mpc, f, f_mask, rows, cols, modulus, binary: bool):
    x_r = read_matrix[typeof(modulus)](f, rows, cols, binary)
    r = read_matrix[typeof(modulus)](f_mask, rows, cols, binary)
    share = x_r.add_mod(r, modulus) if mpc.pid == 2 else r

    return SharedTensor[list[list[typeof(modulus)]]](
        share, x_r, r, modulus, x_r.zeros(),
        x_r.zeros(), False, False, False)


def read_filtered_matrix(mpc, f, f_mask, imask, jmask, rows, cols, offset, multiplicity, modulus, binary):
    share_mats = [list[list[int_t]](rows * multiplicity) for _ in range(multiplicity)]
    x_r_mats = [list[list[int_t]](rows * multiplicity) for _ in range(multiplicity)]
    r_mats = [list[list[int_t]](rows * multiplicity) for _ in range(multiplicity)]
    
    batch_size = 0
    i = offset
    while batch_size < rows:
        if imask[i]: batch_size += 1
        for m in range(multiplicity):
            x_r = read_vector[int_t](f, cols, binary)
            r = read_vector[int_t](f_mask, cols, binary)
            if imask[i]:
                x_r = [x_r[j] for j in range(len(jmask)) if jmask[j]]
                r = [r[j] for j in range(len(jmask)) if jmask[j]]
                r_mats[m].append(r)
                x_r_mats[m].append(x_r)
                share_mats[m].append(x_r.add_mod(r, modulus) if mpc.pid == 2 else r)
        i += 1
    
    svs = [SharedTensor[list[list[int_t]]](
        share_mats[i], x_r_mats[i], r_mats[i], modulus, share_mats[i].zeros(),
        share_mats[i].zeros(), False, False, False) for i in range(multiplicity)]

    return svs


def reset_files(*files):
    for file in files:
        file.seek(0, 0)


def log(name, data, path='log.txt'):
    with open(path, 'a+') as f:
        f.write(f'{name}\n')
        if isinstance(data, list[list]):
            for row in data: f.write(f'{"\t".join([str(e) for e in row])}\n')
        elif isinstance(data, list):
            f.write(f'{"\t".join([str(e) for e in data])}\n')
        else:
            f.write(f'{data}\n')
