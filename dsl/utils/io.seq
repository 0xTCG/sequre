from param import int_t

from ..types.shared_tensor import SharedTensor


def skip_data(f: File, rows: int, cols: int = 0, primes_bytes: int = 0):
    if primes_bytes:
        raise NotImplementedError()
    
    for _ in range(rows): next(f)


def read_vector[TP](f: File, length: int) -> list[TP]:
    return [TP(e.strip()) for e in next(f).split()[:length]]


def read_matrix[TP](f: File, rows: int, cols: int) -> list[list[TP]]:
    return [[TP(e.strip()) for e in next(f).split()[:cols]] for row in range(rows)]


def read_filtered_vector(mpc, f, f_mask, n, modulus):
    x_r = read_vector[int_t](f, n)
    r = read_vector[int_t](f_mask, n)
    share = x_r.add_mod(r, modulus) if mpc.pid == 2 else r

    return SharedTensor[list[int_t]](
        share, x_r, r, modulus, x_r.zeros(),
        x_r.zeros(), False, False, False)


def read_filtered_matrix(mpc, f, f_mask, imask, jmask, rows, cols, offset, multiplicity, modulus):
    share_mats = [list[list[int_t]](rows * multiplicity) for _ in range(multiplicity)]
    x_r_mats = [list[list[int_t]](rows * multiplicity) for _ in range(multiplicity)]
    r_mats = [list[list[int_t]](rows * multiplicity) for _ in range(multiplicity)]
    
    batch_size = 0
    i = offset
    while batch_size < rows:
        if imask[i]: batch_size += 1
        for m in range(multiplicity):
            x_r = read_vector[int_t](f, cols)
            r = read_vector[int_t](f_mask, cols)
            if imask[i]:
                x_r = [x_r[j] for j in range(len(jmask)) if jmask[j]]
                r = [r[j] for j in range(len(jmask)) if jmask[j]]
                r_mats[m].append(r)
                x_r_mats[m].append(x_r)
                share_mats[m].append(x_r.add_mod(r, modulus) if mpc.pid == 2 else r)
        i += 1
    
    svs = [SharedTensor[list[list[int_t]]](
        share_mats[i], x_r_mats[i], r_mats[i], modulus, share_mats[i].zeros(),
        share_mats[i].zeros(), False, False, False) for i in range(multiplicity)]

    return svs


def reset_files(*files):
    for file in files:
        file.seek(0, 0)


def log(mpc, name, data, path='log.txt'):
    if mpc.pid == 2:
        with open(path, 'a+') as f:
            f.write(f'{name}\n')
            if isinstance(data, list[list]):
                for row in data: f.write(f'{"\t".join([str(e) for e in row])}\n')
            elif isinstance(data, list):
                f.write(f'{"\t".join([str(e) for e in data])}\n')
            else:
                f.write(f'{data}\n')
