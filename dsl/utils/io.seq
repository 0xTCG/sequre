from internal.gc import sizeof
from param import int_t

from ..types.shared_tensor import SharedTensor


def write_vector[TP](f: File, vector):
    _C.fwrite(vector.arr.ptr.as_byte(), sizeof(TP), vector.elem_count(), f.fp)
    f._errcheck("error in write")


def write_matrix[TP](f: File, mat):
    for row in mat: write_vector(f, row, TP=TP)


def read_vector[TP](f: File, length: int, binary: bool) -> list[TP]:
    if binary:
        arr = Array[TP](length)
        for i in range(length): arr[i] = ptr[TP](f.read(sizeof(TP)).ptr.as_byte())[0]
        return list[TP](arr, length)
    return [TP(e.strip()) for e in next(f).split()[:length]]


def read_matrix[TP](f: File, rows: int, cols: int, binary: bool) -> list[list[TP]]:
    return [read_vector(f, cols, binary, TP=TP) for _ in range(rows)]


def read_beaver_vector(mpc, f, f_mask, length, modulus, binary: bool):
    x_r = read_vector(f, length, binary, TP=type(modulus))
    r = read_vector(f_mask, length, binary, TP=type(modulus))
    share = x_r.add_mod(r, modulus) if mpc.pid == 2 else r

    return SharedTensor(
        share, x_r, r, modulus, x_r.zeros(),
        x_r.zeros(), False, False, False)


def read_beaver_matrix(mpc, f, f_mask, rows, cols, modulus, binary: bool):
    x_r = read_matrix(f, rows, cols, binary, TP=type(modulus))
    r = read_matrix(f_mask, rows, cols, binary, TP=type(modulus))
    share = x_r.add_mod(r, modulus) if mpc.pid == 2 else r

    return SharedTensor(
        share, x_r, r, modulus, x_r.zeros(),
        x_r.zeros(), False, False, False)


def read_filtered_matrix(mpc, f, f_mask, imask, jmask, rows, cols, offset, multiplicity, modulus, binary):
    share_mats = [list[list[int_t]](rows * multiplicity) for _ in range(multiplicity)]
    x_r_mats = [list[list[int_t]](rows * multiplicity) for _ in range(multiplicity)]
    r_mats = [list[list[int_t]](rows * multiplicity) for _ in range(multiplicity)]
    
    batch_size = 0
    i = offset
    while batch_size < rows:
        if imask[i]: batch_size += 1
        for m in range(multiplicity):
            x_r = read_vector(f, cols, binary, TP=int_t)
            r = read_vector(f_mask, cols, binary, TP=int_t)
            if imask[i]:
                x_r = [x_r[j] for j in range(len(jmask)) if jmask[j]]
                r = [r[j] for j in range(len(jmask)) if jmask[j]]
                r_mats[m].append(r)
                x_r_mats[m].append(x_r)
                share_mats[m].append(x_r.add_mod(r, modulus) if mpc.pid == 2 else r)
        i += 1
    
    svs = [SharedTensor(
        share_mats[i], x_r_mats[i], r_mats[i], modulus, share_mats[i].zeros(),
        share_mats[i].zeros(), False, False, False) for i in range(multiplicity)]

    return svs


def reset_files(*files):
    for file in files:
        file.seek(0, 0)


def log(name, data, path='log.txt', mode='a+', separator='\t'):
    with open(path, mode) as f:
        f.write(f'{name}\n')
        if isinstance(data, list[list]):
            for row in data:
                f.write(separator.join([str(e) for e in row]))
                f.write('\n')
        elif isinstance(data, list):
            f.write(separator.join([str(e) for e in data]))
            f.write('\n')
        else:
            f.write(f'{data}\n')
