from sequre import sequre
from sequre.stdlib.learn.neural_net.constants import SUPPORTED_ACTIVATIONS, RELU_ACTIVATION, LINEAR_ACTIVATION


@sequre
def linear(mpc, x):
    return x


@sequre
def dlinear(mpc, x):
    return x.ones(mpc)


@sequre
def relu(mpc, x):
    return x * (x > 0).astype(type(x._internal_type))


@sequre
def drelu(mpc, x):
    return (x > 0).astype(type(x._internal_type))


def activate(mpc, x, activation: str):
    assert activation in SUPPORTED_ACTIVATIONS, f"Neural net: activation {activation} is not supported"
    
    if activation == RELU_ACTIVATION:
        return relu(mpc, x)
    
    if activation == LINEAR_ACTIVATION:
        return linear(mpc, x)


def dactivate(mpc, x, activation: str):
    assert activation in SUPPORTED_ACTIVATIONS, f"Neural net: activation {activation} is not supported"
    
    if activation == RELU_ACTIVATION:
        return drelu(mpc, x)
    
    if activation == LINEAR_ACTIVATION:
        return dlinear(mpc, x)
