from sequre import sequre
from constants import BGD_OPTIMIZER, SUPPORTED_OPTIMIZERS, SUPPORTED_LOSSES
from loss import loss, dloss


class Sequential[L]:
    layers: L
    loss: str
    optimizer: str

    def __init__(self, layers: L):
        assert staticlen(L) <= 1024, "Sequential model too large: cannot have more than 1024 layers"
        self.layers = layers
    
    def compile(self, mpc, loss: str, optimizer: str, *args, **kwargs) -> Sequential:
        assert loss in SUPPORTED_LOSSES, f"Dense neural net layer: {loss} loss is not supported. Supported losses: {SUPPORTED_LOSSES}"
        assert optimizer in SUPPORTED_OPTIMIZERS, f"Dense neural net layer: {optimizer} optimizer is not supported. Supported optimizers: {SUPPORTED_OPTIMIZERS}"
        self.loss = loss
        self.optimizer = optimizer

        for i in staticrange(1, staticlen(self.layers)):  # Skip input layer
            self.layers[i].initialize(
                mpc, self.layers[i - 1].size, *args, **kwargs)
        
        return self
    
    def fit(self, mpc, X, y, step: float, epochs: int, verbose: bool = True):
        if self.optimizer == BGD_OPTIMIZER:
            self._bgd(mpc, X, y, step, epochs, verbose)
        else:
            raise ValueError(f"Sequential neural net: non-supported optimizer: {self.optimizer}. Supported optimizers: {SUPPORTED_OPTIMIZERS}")
    
    def score(self, mpc, X, y):
        self._forward(mpc, X)
        return self._loss(mpc, y, self.layers[-1].output)
    
    def predict(self, mpc, X):
        self._forward(mpc, X)
        return self.layers[-1].output

    def _score(self, mpc, y):
        assert self.layers[-1].is_evaluated(), "Sequential neural net: cannot calculate training score. Forward pass was never done."
        return self._loss(mpc, y, self.layers[-1].output)
    
    def _bgd(self, mpc, X, y, step: float, epochs: int, verbose: bool):
        for _ in range(epochs):            
            self._forward(mpc, X)
            self._backward(mpc, y)
            self._update(mpc, step)

            if verbose:
                print(f"CP{mpc.pid}:\tSequential neural net: BGD epoch {_ + 1}/{epochs}")
                print(f"CP{mpc.pid}:\t\tTraining score: {self._score(mpc, y).reveal(mpc).sum()}")
    
    def _forward(self, mpc, X):
        last_output = X
        for layer in self.layers:
            layer.evaluate(mpc, last_output)
            last_output = layer.output
    
    def _backward(self, mpc, y):
        assert self.layers[-1].is_evaluated(), "Sequenital neural net: there it no output: backward pass possibly ran before or without the forward pass"
        dhidden = self._dloss(mpc, y, self.layers[-1].output)
        for i in staticrange(1, staticlen(self.layers)):
            idx: Static[int] = staticlen(self.layers) - i
            prev_output = self.layers[idx - 1].output
            dhidden = self.layers[idx].derive(mpc, prev_output, dhidden)
    
    def _update(self, mpc, step: float):
        for layer in self.layers[1:]:
            layer.update(mpc, step)
    
    def _loss(self, mpc, y, output):
        return loss(mpc, y, output, self.loss)
    
    def _dloss(self, mpc, y, output):
        return dloss(mpc, y, output, self.loss)
