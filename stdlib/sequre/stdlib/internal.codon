import prg

from helpers import argmin

from ..utils.param import int_t, NBIT_K, NBIT_F, DEBUG
from ..types.shared_tensor import SharedTensor
from ..types.utils import double_to_fp

from fp import fp_div, fp_sqrt


TP = int_t


class Internal:
    def secure_evalp(mpc, x_, coefs_, exps_):
        x_r = []
        r = []

        for sn in x_:
            x_r_, r_ = sn.get_partitions(mpc, force=False)
            x_r.append(x_r_)
            r.append(r_)

        coefs = [int_t(coefs_[i])
                    for i in range(len(coefs_))]
        exps = [[exps_[i + j] for j in range(len(x_))]
                for i in range(0, len(exps_), len(x_))]
        
        result = mpc.polynomial._beaver_evaluate_poly(
            x_r, r, coefs, exps, x_[0].modulus)
        sv = SharedTensor(result, x_[0].modulus)
        sv.fp = x_[0].is_fp()
        
        # TODO: #23 Handle sqrts and partitions

        return sv

    def secure_add(mpc, x, y):
        if isinstance(x, float):
            return Internal.__add_public(mpc, x.to_fp(y.modulus), y, False)
        elif isinstance(y, float):
            return Internal.__add_public(mpc, y.to_fp(x.modulus), x, False)
        elif isinstance(x, int):
            return Internal.__add_public(mpc, x.to_fp(y.modulus) if y.fp else int_t(x), y, False)
        elif isinstance(y, int):
            return Internal.__add_public(mpc, y.to_fp(x.modulus) if x.fp else int_t(y), x, False)
        elif isinstance(x, SharedTensor[list[list[int_t]]]) and isinstance(y, SharedTensor[list[int_t]]):
            return x.broadcast_add(y)
        elif isinstance(x, SharedTensor[list[int_t]]) and isinstance(y, SharedTensor[int_t]):
            return x.broadcast_add(y)
        else:
            if not x.is_public() and not y.is_public():
                return x + y
            elif x.is_public():
                return Internal.__add_public(mpc, x.share, y, x.diagonal)
            elif y.is_public():
                return Internal.__add_public(mpc, y.share, x, y.diagonal)
            
            raise TypeError("Invalid type of addends in secure add")

    def secure_sub(mpc, x, y):
        if isinstance(x, float):
            return Internal.__add_public(mpc, x.to_fp(y.modulus), -y, False)
        elif isinstance(y, float):
            return Internal.__add_public(mpc, (-y).to_fp(x.modulus), x, False)
        elif isinstance(x, int):
            return Internal.__add_public(mpc, x.to_fp(y.modulus) if y.fp else int_t(x), -y, False)
        elif isinstance(y, int):
            return Internal.__add_public(mpc, (-y).to_fp(x.modulus) if x.fp else (x.modulus - y), x, False)
        elif isinstance(x, SharedTensor[list[list[int_t]]]) and isinstance(y, SharedTensor[list[int_t]]):
            return x.broadcast_add(-y)
        elif isinstance(x, SharedTensor[list[int_t]]) and isinstance(y, SharedTensor[int_t]):
            return x.broadcast_add(-y)
        else:
            if not x.is_public() and not y.is_public():
                return x + (-y)
            elif x.is_public():
                return Internal.__add_public(mpc, x.share, -y, x.diagonal)
            elif y.is_public():
                return Internal.__add_public(mpc, y.share.neg_mod(x.modulus), x, y.diagonal)
            
            raise TypeError("Invalid type of addends in secure_sub")

    def secure_mul(mpc, x, y):
        if isinstance(y, float):
            y_fp = double_to_fp(y, x.modulus)
            sv = x * y_fp
            # TODO: #117 Implement clever joint truncations pattern matcher
            if x.is_fp(): sv = sv.trunc(mpc.fp)
            sv.fp = True
            return sv
        else:
            if x.public or y.public:
                c_share = x.share.mul_mod(y.share, x.modulus if y.public else y.modulus)
                sv = SharedTensor(c_share, x.modulus if y.public else y.modulus)
                sv.fp = x.is_fp() or y.is_fp()
                return sv
            
            if DEBUG: assert x.modulus == y.modulus, f"Non-matching moduli for factors: {x.modulus} != {y.modulus}"
            modulus = x.modulus

            x_1_r, r_1 = x.get_partitions(mpc, force=False)
            x_2_r, r_2 = y.get_partitions(mpc, force=False)

            c = mpc.arithmetic.__beaver_mul(x_1_r, r_1, x_2_r, r_2, modulus)
            c = mpc.arithmetic.__beaver_reconstruct(c, modulus)

            if x.is_fp() and y.is_fp():
                c = mpc.fp.trunc(c, modulus)
            
            sv = SharedTensor(c, modulus)
            sv.fp = x.is_fp() or y.is_fp()

            # TODO: #23 Efficiently calculate beaver partitions of c here
            # Bellow is temp dirty solution for beaver partitioning which should be both:
            # - Computed with less network overhead
            # - Computed only if compiler figures out that partitions will be needed downstream
            # sv.set_partitions(mpc.arithmetic.__beaver_partition(sv.share, modulus))

            # TODO: #23 Check if there is a better way to do this
            # if x.sqrt and y.sqrt:
            #     sv.sqrt = mpc.arithmetic.multiply(x.sqrt, y.sqrt, modulus)
            #     sv.sqrt = mpc.fp.trunc(sv.sqrt, modulus)
            #     sv.sqrt_inv = mpc.arithmetic.multiply(x.sqrt_inv, y.sqrt_inv, modulus)
            #     sv.sqrt_inv = mpc.fp.trunc(sv.sqrt_inv, modulus)
            return sv

    def secure_mul_no_cache(mpc, x_, y_):
        if isinstance(y_, float):
            y_fp = double_to_fp(y_, x_.modulus)
            sv = x_ * y_fp
            # TODO: #117 Implement clever joint truncations pattern matcher
            if x_.is_fp(): sv = sv.trunc(mpc.fp)
            sv.fp = True
            return sv
        else:
            if DEBUG: assert x_.modulus == y_.modulus
            modulus = x_.modulus
            x = x_.share
            y = y_.share

            c = mpc.arithmetic.multiply(x, y, modulus)

            if x_.is_fp() and y_.is_fp():
                c = mpc.fp.trunc(c, modulus)

            sv = SharedTensor(c, modulus)
            sv.fp = x_.is_fp() or y_.is_fp()

            return sv

    def secure_pow(mpc, x_, p):
        modulus = x_.modulus

        if x_.is_fp():
            # TODO: #58 Implement efficient pows calculation for FPs
            return Internal.secure_pow_no_cache(mpc, x_, p)

        x_r, r = x_.get_partitions(mpc, force=False)
        c = mpc.polynomial.powers_cached(x_r, r, p, modulus)[p]
        
        sv = SharedTensor(c, modulus)
        sv.fp = x_.is_fp()

        # TODO: #23 Efficiently calculate beaver partitions of c here
        # TODO: #23 Check if there is a way to calculate cached sqrts efficiently
        return sv

    def secure_pow_no_cache(mpc, x_, p):
        modulus = x_.modulus
        x = x_.share

        for _ in range(p - 1):
            x = mpc.arithmetic.multiply(x, x_.share, modulus)
            if x_.is_fp(): x = mpc.fp.trunc(x, modulus)
        
        sv = SharedTensor(x, modulus)
        sv.fp = x_.is_fp()

        return sv

    def secure_div(mpc, x, y):
        # TODO: #26 Currently does not work for complex algebraic structures.
        # Resolve issue #26 and change code below in order to fix this.
        if isinstance(x, int) or isinstance(x, float):
            if isinstance(y.share, list):
                sv = SharedTensor([double_to_fp(float(x), y.modulus) for _ in range(len(y.share))], y.modulus)
                return fp_div(mpc, sv, y)
            else:
                sv = SharedTensor(double_to_fp(float(x), y.modulus), y.modulus)
                return fp_div(mpc, sv, y)
        elif isinstance(y, float) or isinstance(y, int):
            sv = x * double_to_fp(1.0 / y, x.modulus)
            if x.is_fp(): sv = sv.trunc(mpc.fp)
            return sv
        else:
            # TODO: Efficiently calculate beaver partitions of sv here
            return fp_div(mpc, x, y)
    
    def secure_gt(mpc, x, y):
        # TODO: #26 Currently does not work for complex algebraic structures.
        # Resolve issue #26 and change code below in order to fix this.
        if isinstance(y, int) or isinstance(y, TP):
            modulus = x.modulus
            if y == 0:
                return SharedTensor(mpc.boolean.is_positive(x.share, modulus), modulus)

            return SharedTensor(mpc.boolean.greater_than_public(x.share, TP(y), modulus), modulus)
        elif isinstance(y, float):
            modulus = x.modulus
            return SharedTensor(mpc.boolean.greater_than_public(x.to_fp().share, double_to_fp(y, modulus), modulus), modulus)
        else:
            if DEBUG: assert x.modulus == y.modulus
            modulus = x.modulus
            return SharedTensor(mpc.boolean.greater_than(x.share, y.share, modulus), modulus)
        
        # TODO: Efficiently calculate beaver partitions of sv here

    def secure_lt(mpc, x, y):
        # TODO: #26 Currently does not work for complex algebraic structures.
        # Resolve issue #26 and change code below in order to fix this.
        if isinstance(y, int) or isinstance(y, TP):
            modulus = x.modulus
            if y == 0:
                return SharedTensor(mpc.boolean.is_positive(x.share.neg_mod(modulus), modulus), modulus)
            
            return SharedTensor(mpc.boolean.less_than_public(x.share, TP(y), modulus), modulus)
        elif isinstance(y, float):
            modulus = x.modulus
            return SharedTensor(mpc.boolean.less_than_public(x.to_fp().share, double_to_fp(y, modulus), modulus), modulus)
        else:
            if DEBUG: assert x.modulus == y.modulus
            modulus = x.modulus
            return SharedTensor(mpc.boolean.less_than(x.share, y.share, modulus), modulus)
        
        # TODO: #23 Efficiently calculate beaver partitions of sv here
    
    def secure_eq(mpc, x, y):
        if x.modulus.popcnt() == 1:
            # TODO: #158 Make comparisons stable on rings.
            l = Internal.secure_gt(mpc, Internal.secure_sub(mpc, x, y), 0)
            r = Internal.secure_gt(mpc, Internal.secure_sub(mpc, y, x), 0)
            return Internal.secure_sub(mpc, 1, Internal.secure_add(mpc, l, r))

        sub = Internal.secure_sub(mpc, x, y)
        is_pos = Internal.secure_gt(mpc, Internal.secure_mul(mpc, sub, sub), 0)
        return Internal.secure_sub(mpc, 1, is_pos)

    def secure_sqrt_inv(mpc, x, y):
        # TODO: #26 Currently does not work for complex algebraic structures.
        # Resolve issue #26 and change code below in order to fix this.
        
        if not y.sqrt_inv:
            s, sinv = fp_sqrt(mpc, y)
            y.sqrt, y.sqrt_inv = s.share, sinv.share
        
        if isinstance(x, int):
            sv = SharedTensor(y.sqrt_inv, y.modulus)
            sv.fp = True
            # TODO: #23 Efficiently calculate beaver partitions of c here
            # Bellow is temp dirty solution for beaver partitioning which should be both:
            # - Computed with less network overhead
            # - Computed only if compiler figures out that partitions will be needed downstream
            # sv.set_partitions(mpc.arithmetic.__beaver_partition(sv.share, modulus))
            return sv * x
        else:
            if DEBUG: assert x.modulus == y.modulus
            modulus = x.modulus
            
            x_1_r, r_1 = x.get_partitions(mpc, force=False)
            x_2_r, r_2 = mpc.arithmetic.__beaver_partition(y.sqrt_inv, modulus)
            
            c = mpc.arithmetic.__beaver_mul(x_1_r, r_1, x_2_r, r_2, modulus)
            c = mpc.arithmetic.__beaver_reconstruct(c, modulus)
            if x.is_fp():
                c = mpc.fp.trunc(c, modulus)
            
            sv = SharedTensor(c, modulus)
            sv.fp = True
            # TODO: #23 Efficiently calculate beaver partitions of c here
            # Bellow is temp dirty solution for beaver partitioning which should be both:
            # - Computed with less network overhead
            # - Computed only if compiler figures out that partitions will be needed downstream
            # sv.set_partitions(mpc.arithmetic.__beaver_partition(sv.share, modulus))
            
            return sv

    def secure_sqrt_inv_no_cache(mpc, x, y):
        # TODO: #26 Currently does not work for complex algebraic structures.

        sqrt_inv = fp_sqrt(mpc, y)[1].share
        
        if isinstance(x, int):
            sv = SharedTensor(sqrt_inv, y.modulus)
            sv.fp = True
            return sv * x
        else:
            if DEBUG: assert x.modulus == y.modulus
            modulus = x.modulus

            result = mpc.arithmetic.multiply(x.share, sqrt_inv, modulus)
            if x.is_fp(): result = mpc.fp.trunc(result, modulus)
            sv = SharedTensor(result, modulus)
            sv.fp = True
            
            return sv
    
    def powers(mpc, x_, p):
        modulus = x_.modulus

        if x_.is_fp():
            # TODO: #58 Implement efficient pows calculation for FPs
            raise NotImplementedError("Powers method not yet implemented for fixed-point shared tensors.")

        x_r, r = x_.get_partitions(mpc, force=False)

        pows = mpc.polynomial.powers_cached(
            x_r, r, p, modulus)
        
        sv = SharedTensor(pows, modulus)

        # TODO: #23 Efficiently calculate beaver partitions of c here
        # TODO: #23 Check if there is a way to calculate cached sqrts efficiently
        return sv

    def dot(mpc, x, y):
        if DEBUG: assert x.modulus == y.modulus
        modulus = x.modulus

        x_1_r, r_1 = x.get_partitions(mpc, force=False)
        x_2_r, r_2 = y.get_partitions(mpc, force=False)

        c = mpc.arithmetic.__beaver_dot_prod(x_1_r, r_1, x_2_r, r_2, modulus)
        c = mpc.arithmetic.__beaver_reconstruct(c, modulus)

        if x.is_fp() and y.is_fp():
            c = mpc.fp.trunc(c, modulus)
        
        sv = SharedTensor(c, modulus)
        sv.fp = x.is_fp() or y.is_fp()
        # TODO: #23 Efficiently calculate beaver partitions of sv here
        # Bellow is temp dirty solution for beaver partitioning which should be both:
        # - Computed with less network overhead
        # - Computed only if compiler figures out that partitions will be needed downstream
        # sv.set_partitions(mpc.arithmetic.__beaver_partition(sv.share, modulus))
        
        return sv

    def dot(mpc, x):
        return Internal.dot(mpc, x, x)

    def matmul(mpc, x, y):
        if DEBUG: assert x.modulus == y.modulus
        modulus = x.modulus

        x_1_r, r_1 = x.get_partitions(mpc, force=False)
        x_2_r, r_2 = y.get_partitions(mpc, force=False)

        c = mpc.arithmetic.__beaver_matmul(x_1_r, r_1, x_2_r, r_2, modulus)
        c = mpc.arithmetic.__beaver_reconstruct(c, modulus)

        if x.is_fp() and y.is_fp():
            c = mpc.fp.trunc(c, modulus)
        
        sv = SharedTensor(c, modulus)
        sv.fp = x.is_fp() or y.is_fp()

        # TODO: #23 Efficiently calculate beaver partitions of sv here
        # Bellow is temp dirty solution for beaver partitioning which should be both:
        # - Computed with less network overhead
        # - Computed only if compiler figures out that partitions will be needed downstream
        # sv.set_partitions(mpc.arithmetic.__beaver_partition(sv.share, modulus))
        
        # TODO: #23 Check if there is a better way to do this
        # if x.sqrt and y.sqrt:
        #     sv.sqrt = mpc.arithmetic.multiply(x.sqrt, y.sqrt, modulus)
        #     sv.sqrt = mpc.fp.trunc(sv.sqrt, modulus)
        #     sv.sqrt_inv = mpc.arithmetic.multiply(x.sqrt_inv, y.sqrt_inv, modulus)
        #     sv.sqrt_inv = mpc.fp.trunc(sv.sqrt_inv, modulus)
        
        return sv

    def matmul(mpc, x, y, z):
        return Internal.matmul(mpc, Internal.matmul(mpc, x, y), z)

    def sqrt(mpc, x):
        # TODO: #26 Currently does not work for complex algebraic structures.
        # Resolve issue #26 and change code below in order to fix this.
        if not x.sqrt:
            s, sinv = fp_sqrt(mpc, x)
            x.sqrt, x.sqrt_inv = s.share, sinv.share
        
        sv = SharedTensor(x.sqrt, x.modulus)
        sv.fp = True
        # TODO: #23 Efficiently calculate beaver partitions of sv here
        return sv

    def broadcast(mpc, value):
        value.share = mpc.comms.broadcast(value.share, value.modulus)
        value.public = True
        return value

    def dist(mpc, shape, name, modulus, params):
        if name == 'normal':
            rows, cols = shape
            gaussian = [[double_to_fp(prg.gauss(*params), modulus) if mpc.pid == 0 else TP(0)
                        for _ in range(cols)] for _ in range(rows)]
            gaussian = mpc.comms.share(gaussian, modulus)

            stensor = SharedTensor(gaussian, modulus)
            stensor.fp = True

            return stensor

        raise NotImplementedError(f'Distribution {name} not implemented yet.')
    
    def min_cost_router(new_vars, cost_vars):
        return new_vars[argmin(cost_vars)]

    def __add_public(mpc, x_public, y, diagonal):
        share = y.share
        modulus = y.modulus

        if isinstance(share, list[list]) and isinstance(x_public, list[list]):
            if diagonal:
                for i in range(len(share)):
                    share[i][i] = mpc.arithmetic.add_public(share[i][i], x_public[i][i], modulus)
            else: share = mpc.arithmetic.add_public(share, x_public, modulus)
        else: share = mpc.arithmetic.add_public(share, x_public, modulus)
        
        sv = SharedTensor(share, modulus)
        sv.fp = y.fp

        if y.sqrt:
            sv.sqrt = type(share)(0)
            sv.sqrt_inv = type(share)(0)
        
        if not y.is_partitioned():
            return sv
        
        sv.x_r = y.x_r.add_mod(x_public, modulus)
        sv.r = y.r

        return sv
