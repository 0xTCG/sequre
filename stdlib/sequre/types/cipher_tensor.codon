import operator

from numpy.ndarray import ndarray
from numpy.create import array
from pickler import pickle, unpickle

from sequre.lattiseq.ckks import Ciphertext, Plaintext
from sequre.utils.utils import one_hot_vector


class CipherTensor[ctype]:
    _data: list[ctype]
    shape: list[int]
    slots: int
    _chunk_size: int
    _transposed: bool

    def __init__(self, _data: list[ctype], shape: list[int], slots: int, _transposed: bool):
        self.__init__(_data, shape, slots)
        self._transposed = _transposed
    
    def __init__(self, _data: list[ctype], shape: list[int], slots: int):
        self.__init__(shape, slots)
        self._data = _data
    
    def __init__(self, shape: list[int], slots: int):
        self._data = []
        self.shape = shape
        self.slots = slots
        self._transposed = False
        self._reset_chunk_size()
    
    def __bool__(self) -> bool:
        return bool(self._data)
    
    def __repr__(self) -> str:
        return f"""
            Ciphertensor:
            \tShape: {self.shape}
            \tSlots: {self.slots}
            \tTransposed: {self._transposed}
            \t(Ciphertensor elements cannot be printed in a bulk)
        """
    
    def __iter__(self):
        for i in range(self.shape[0]):
            yield self[i]

    def __pickle__(self, jar: Jar, pasteurized: bool):
        pickle(self._transposed, jar, pasteurized)
        if not pasteurized: jar += self._transposed._pickle_size()
        pickle(self.slots, jar, pasteurized)
        if not pasteurized: jar += self.slots._pickle_size()
        pickle(self.shape, jar, pasteurized)
        if not pasteurized: jar += self.shape._pickle_size()
        pickle(self._data, jar, pasteurized)
    
    def __unpickle__(jar: Jar, pasteurized: bool) -> CipherTensor[ctype]:
        _transposed = unpickle(jar, pasteurized, bool)
        if not pasteurized: jar += _transposed._pickle_size()
        slots = unpickle(jar, pasteurized, int)
        if not pasteurized: jar += slots._pickle_size()
        shape = unpickle(jar, pasteurized, list[int])
        if not pasteurized: jar += shape._pickle_size()
        _data = unpickle(jar, pasteurized, List[ctype])

        return CipherTensor[ctype](
            _data=_data,
            shape=shape,
            slots=slots,
            _transposed=_transposed)
    
    def copy(self) -> CipherTensor[ctype]:
        return CipherTensor[ctype](
            _data=self._data.copy(),
            shape=self.shape.copy(),
            slots=self.slots,
            _chunk_size=self._chunk_size,
            _transposed=self._transposed)

    def _pickle_size(self) -> int:
        return self._transposed._pickle_size() + self.slots._pickle_size() + self.shape._pickle_size() + self._data._pickle_size()

    @property
    def cipher_shape(self):
        cs = self.shape.copy()
        cs[-1] = (cs[-1] + self.slots - 1) // self.slots
        return cs
    
    @property
    def ndim(self):
        return len(self.shape)
    
    @property
    def T(self) -> CipherTensor[ctype]:
        return CipherTensor[ctype](
            _data=self._data.copy(),
            shape=self.shape,
            slots=self.slots,
            _chunk_size=self._chunk_size,
            _transposed=self._transposed ^ True)
    
    def __add__(self: CipherTensor[ctype], other) -> CipherTensor[ctype]:
        raise NotImplementedError("CipherTensors cannot be added without IR pass enabled.")

    def __sub__(self: CipherTensor[ctype], other) -> CipherTensor[ctype]:
        raise NotImplementedError("CipherTensors cannot be subtracted without IR pass enabled.")
    
    def __mul__(self: CipherTensor[ctype], other) -> CipherTensor[ctype]:
        raise NotImplementedError("CipherTensors cannot be multiplied without IR pass enabled.")

    def __matmul__(self: CipherTensor[ctype], other) -> CipherTensor[ctype]:
        raise NotImplementedError("CipherTensors matrices cannot be multiplied without IR pass enabled.")

    def __gt__(self: CipherTensor[ctype], other) -> CipherTensor[ctype]:
        raise NotImplementedError("CipherTensors cannot be compared without IR pass enabled.")

    def __lt__(self: CipherTensor[ctype], other) -> CipherTensor[ctype]:
        raise NotImplementedError("CipherTensors cannot be compared without IR pass enabled.")

    def __eq__(self, other: CipherTensor[ctype]) -> bool:
        if self.shape != other.shape or self.slots != other.slots: return False
        return self._data == other._data
    
    def __getitem__(self, i: int) -> CipherTensor[ctype]:
        assert self.ndim > 1, "CipherTensor: Cannot getitem from one-dimensional CipherTensor."
        
        if self._transposed:
            print("INFO: getitem on transposed ciphertensor fetches column instead of row")
        
        return CipherTensor[ctype](
            _data=self._data[i * self._chunk_size:(i + 1) * self._chunk_size],
            shape=self.shape[1:],
            slots=self.slots)

    def __getitem__(self, s: slice) -> CipherTensor[ctype]:
        if self._transposed:
            print("INFO: getitem on transposed ciphertensor fetches column instead of row")
        
        shape = self.shape.copy()
        shape[0] = s.stop - s.start

        start = s.start * self._chunk_size
        end = s.stop * self._chunk_size
        
        return CipherTensor[ctype](
            _data=self._data[start:end],
            shape=shape,
            slots=self.slots)

    def getitemdup(self, mpc, i: int) -> CipherTensor[ctype]:
        assert self.ndim == 1, "CipherTensor: getitemdup can be only from one-dimensional CipherTensor."
        return self.mask(mpc, i).reduce_add(mpc, self.shape[0])
    
    def mask(self, mpc, i: int) -> CipherTensor[ctype]:
        assert self.ndim == 1, "CipherTensor: Only one-dimensional CipherTensors can be masked."
        return self.mul(mpc, one_hot_vector(i, self.shape[0], TP=float))

    @staticmethod
    def _count(shape):
        if len(shape) == 0:
            return 0
        total = 1
        for i in range(len(shape)):
            total *= shape[i]
        return total

    @staticmethod
    def _count_ciphers(shape, slots):
        if len(shape) == 0:
            return 0
        total = 1
        for i in range(len(shape) - 1):
            total *= shape[i]
        return (shape[-1] + slots - 1) // slots * total
    
    def destroy(self):
        self._data.clear()
        self.shape.clear()
        self.slots = 0
        self._chunk_size = 0
        self._transposed = False
    
    @staticmethod
    def enc(mpc, data) -> CipherTensor[ctype]:
        if isinstance(data, ndarray):
            assert data.ndim <= 2, "CipherTensor can encode/encrypt only the ndarrays of dimension less than 3 at the moment"
            data_list = data.tolist()
        elif isinstance(data, list):
            data_list = data
        else:
            compile_error("CipherTensor: Invalid input for ciphertensor encoding/encryption")
        
        shape = data_list.shape
        vec_len = shape[-1]
        slots = mpc.he.crypto_params.params.slots()
        number_of_elements = CipherTensor._count_ciphers(shape, slots)
        vector_generator = data_list.generate_vectors()

        _data = List[ctype](number_of_elements)
        for _ in range(0, CipherTensor._count(shape), vec_len):
            _data.extend(mpc.he.enc_vector(next(vector_generator), T=ctype))
        
        assert (shape[-1] + slots - 1) // slots * shape[:-1].reduce_mul() == len(_data), f"(INTERNAL ERROR) CipherTensor: Input data shapes do not match encryption/encoding shape. Input shape: {data.shape}. Enc vector len: {len(_data)}. Slots: {slots}"

        return CipherTensor[ctype](
            _data=_data,
            shape=shape,
            slots=slots)

    @staticmethod
    def zeros(mpc, shape: List[int]) -> CipherTensor[Ciphertext]:
        slots = mpc.he.crypto_params.params.slots()
        number_of_elements = CipherTensor._count_ciphers(shape, slots)
        
        return CipherTensor[Ciphertext](
            _data=[mpc.he.zero_cipher() for _ in range(number_of_elements)],
            shape=shape,
            slots=slots)

    def decrypt(self, mpc) -> CipherTensor[Plaintext]:
        assert isinstance(ctype, Ciphertext), "Ciphertensor: Data already decrypted"
        return CipherTensor[Plaintext](
            _data=mpc.he.collective_decrypt_vector(self._data, mpc.comms.hub_pid),
            shape=self.shape,
            slots=self.slots,
            _transposed=self._transposed)
    
    def decode[T](self, mpc) -> ndarray:
        assert isinstance(ctype, Plaintext), "Ciphertensor: Make sure to decrypt the ciphertensor before decoding it"
        assert 0 < self.ndim < 3, "Ciphertensor: Only 1-dim and 2-dim ciphertensors can be revealed at the moment"

        new_shape = self.shape[:-1]
        last_lane = (self.shape[-1] + self.slots - 1) // self.slots * self.slots
        new_shape.append(last_lane)
        decoded_vector = mpc.he.decode_vector(self._data, DTP=T)

        assert (decoded_vector.size() + self.slots - 1) // self.slots == len(self._data) == self.cipher_shape.reduce_mul(), f"CipherTensor: Input data shapes do not match encryption/encoding shape. Input shape: {decoded_vector.shape}. Enc vector len: {len(self._data)}. Slots: {self.slots}. Cipher shape: {self.cipher_shape}"

        new_shape_tuple = (1, new_shape[0]) if self.ndim == 1 else (new_shape[0], new_shape[1])
        shape_tuple = (1, self.shape[0]) if self.ndim == 1 else (self.shape[0], self.shape[1])
        arr = array(decoded_vector, dtype=T).reshape(new_shape_tuple).resize(shape_tuple)
        return arr.T if self._transposed else arr
    
    def reveal[T](self, mpc) -> ndarray:
        plain = self.decrypt(mpc) if isinstance(ctype, Ciphertext) else self
        return plain.decode(mpc, T=T)
    
    def append(self, other: CipherTensor[ctype]):
        assert not self._transposed and not other._transposed, "Ciphertensor: Appending transposed ciphertensors is not implemented yet"
        assert self.ndim > 1, "Ciphertensor: Cannot append to one-dimensional Ciphertensor"
        assert self.shape[1:] == other.shape, "Ciphertensor: Invalid shapes for append"
        self._data.extend(other._data)
        self.shape[0] += 1
    
    def pop(self):
        assert not self._transposed, "Ciphertensor: Popping transposed ciphertensor is not implemented yet"
        assert self.ndim > 1, "CipherTensor: Cannot pop from one-dimensional CipherTensor"
        self._data.len -= self._chunk_size
        self.shape[0] -= 1

    def extendleft(self, other: CipherTensor[ctype]):
        assert not self._transposed and not other._transposed, "Ciphertensor: Extending transposed ciphertensors is not implemented yet"
        assert self.shape[1:] == other.shape[1:], "CipherTensor: Invalid shapes for extend"

        _data = other._data.copy()
        _data.extend(self._data)
        self._data = _data
        self.shape[0] += other.shape[0]
    
    def extend(self, other: CipherTensor[ctype]):
        assert not self._transposed and not other._transposed, "Ciphertensor: Extending transposed ciphertensors is not implemented yet"
        assert self.shape[1:] == other.shape[1:], "CipherTensor: Invalid shapes for extend"

        self._data.extend(other._data)
        self.shape[0] += other.shape[0]
    
    def concat(self, mpc, other: CipherTensor[ctype], axis: int) -> CipherTensor[ctype]:
        assert not self._transposed and not other._transposed, "Ciphertensor: Concatenating transposed ciphertensors is not implemented yet"
        assert axis <= 1 and self.ndim == 2, "CipherTensor concat not yet enabled for arbitrary ndim tensor. Internal note: Switch to ndarray to enable this"  # TODO
        assert self.shape[axis ^ 1] == other.shape[axis ^ 1], "CipherTensor: Incompatible shapes for concatenation along provided axis"
        assert self.slots == other.slots, "CipherTensor: Incompatible slots for concatenation"
        
        if axis == 0:
            _data = self._data.copy()
            _data.extend(other._data)
        else:
            offset = self.shape[axis] % self.slots
            _data = []
            for self_row, other_row in zip(self, other):
                _data.extend(self_row._data)
                if offset == 0:
                    _data.extend(other_row._data)
                else:
                    rotated_other = other_row.shift(mpc, self.slots - offset)
                    mask = mpc.he.enc_vector([(1.0 if i < offset else 0.0) for i in range(self.slots)], T=Plaintext)
                    mpc.he.imul([_data[-1]], mask)
                    mpc.he.iadd([_data[-1]], [rotated_other._data[0]])
                    _data.extend(rotated_other._data[1:])

                    if other.shape[axis] < self.slots - offset:
                        _data.pop()
        
        _shape = self.shape.copy()
        _shape[axis] += other.shape[axis]

        return CipherTensor[ctype](
            _data=_data,
            shape=_shape,
            slots=self.slots)
    
    def iadd(self, mpc, other) -> CipherTensor[Ciphertext]:
        assert not isinstance(ctype, Plaintext), "Ciphertensor: Cannot add to plaintext inplace"
        other_cipher = self._check_other_operand_elem_wise(mpc, other)
        assert self.shape == other_cipher.shape, f"CipherTensor.iadd: Shapes mismatch: {self.shape} != {other_cipher.shape}"

        mpc.he.iadd(self._data, other_cipher._data)
        return self

    def isub(self, mpc, other) -> CipherTensor[Ciphertext]:
        assert not isinstance(ctype, Plaintext), "Ciphertensor: Cannot subtract from plaintext inplace"
        other_cipher = self._check_other_operand_elem_wise(mpc, other)
        assert self.shape == other_cipher.shape, f"CipherTensor.iadd: Shapes mismatch: {self.shape} != {other_cipher.shape}"

        mpc.he.isub(self._data, other_cipher._data)
        return self

    def imul(self, mpc, other) -> CipherTensor[Ciphertext]:
        assert not isinstance(ctype, Plaintext), "Ciphertensor: Cannot multiply plaintext inplace"
        other_cipher = self._check_other_operand_elem_wise(mpc, other)
        assert self.shape == other_cipher.shape, f"CipherTensor.imul: Shapes mismatch: {self.shape} != {other_cipher.shape}"

        mpc.he.imul(self._data, other_cipher._data)
        return self

    def add(self, mpc, other):
        if isinstance(ctype, Plaintext) and isinstance(other, CipherTensor[Ciphertext]):
            return other.add(mpc, self)
        elif isinstance(ctype, Plaintext):
            return self._handle_plaintext_case(mpc, other, operator.add)
        
        other_cipher = self._check_other_operand_elem_wise(mpc, other)
        assert self.shape == other_cipher.shape, f"CipherTensor.add: Shapes mismatch: {self.shape} != {other_cipher.shape}"

        return CipherTensor[Ciphertext](
            _data=mpc.he.add(self._data, other_cipher._data),
            shape=self.shape,
            slots=self.slots,
            _transposed=self._transposed)

    def sub(self, mpc, other):
        assert not (isinstance(ctype, Plaintext) and isinstance(other, CipherTensor[Ciphertext])), "Ciphertensor: (Not implemented yet) Cannot subtract ciphertext from plaintext"
        if isinstance(ctype, Plaintext):
            return self._handle_plaintext_case(mpc, other, operator.sub)
        
        other_cipher = self._check_other_operand_elem_wise(mpc, other)
        assert self.shape == other_cipher.shape, f"CipherTensor.add: Shapes mismatch: {self.shape} != {other_cipher.shape}"

        return CipherTensor[Ciphertext](
            _data=mpc.he.sub(self._data, other_cipher._data),
            shape=self.shape,
            slots=self.slots,
            _transposed=self._transposed)
    
    def mul(self, mpc, other):
        if isinstance(ctype, Plaintext) and isinstance(other, CipherTensor[Ciphertext]):
            return other.mul(mpc, self)
        elif isinstance(ctype, Plaintext):
            return self._handle_plaintext_case(mpc, other, operator.mul)
        
        other_cipher = self._check_other_operand_elem_wise(mpc, other)
        assert self.shape == other_cipher.shape, f"CipherTensor.mul: Shapes mismatch: {self.shape} != {other_cipher.shape}"

        return CipherTensor[Ciphertext](
            _data=mpc.he.mul(self._data, other_cipher._data),
            shape=self.shape,
            slots=self.slots,
            _transposed=self._transposed)

    def rotate(self, mpc, step: int) -> CipherTensor[Ciphertext]:
        return CipherTensor[Ciphertext](
            _data=mpc.he.rotate(self._data, step),
            shape=self.shape,
            slots=self.slots,
            _transposed=self._transposed)

    def shift(self, mpc, step: int) -> CipherTensor[ctype]:
        """
        Note: Shifting adds an extra ciphertext to the tensor and starts with (self.slots - step) number of zeros.
        Warning: This changes the shape of the ciphertensor. All zeros will be included in the rotated Ciphertensor.
        Example: [] - CipherTensor, () - Single ciphertext
            [(1, 2, 3, 4), (5, 6, 7, 8)].shift(2) -> [(0, 0, 1, 2), (3, 4, 5, 6), (7, 8, 0, 0)]
        """
        assert step <= self.slots, "Ciphertensor: Shifting requires step to be less than the number of slots per each cipher"

        rotated_tensor = self.rotate(mpc, step)
        
        mask = [(0 if (i % self.slots < self.slots - step) else 1) for i in range(len(self._data) * self.slots)]
        maks_enc = mpc.he.enc_vector(mask, T=Plaintext)
        mask_inv_enc = mpc.he.enc_vector(mask ^ 1, T=Plaintext)
        
        offset_tensor_data = mpc.he.mul(rotated_tensor._data, maks_enc)
        offset_tensor_data.append(mpc.he.zero_cipher())
        main_tensor_data = mpc.he.mul(rotated_tensor._data, mask_inv_enc)
        main_tensor_data.insert(0, mpc.he.zero_cipher())

        shape = self.shape.copy()
        shape[-1] = (self.cipher_shape[-1] + 1) * self.slots

        return CipherTensor[ctype](
            _data=mpc.he.add(main_tensor_data, offset_tensor_data),
            shape=shape,
            slots=self.slots,
            _transposed=self._transposed)

    def reduce_add(self, mpc, new_size: int) -> CipherTensor[ctype]:
        assert self.ndim == 1, "CipherTensor: Addition reduction can be applied only to 1-dimensional tensors"

        if isinstance(ctype, Plaintext):
            # TODO: Read dtype (T) from other (add dtype static to CipherTensor class)
            _sum: float = self.decode(mpc, T=float).sum()
            return CipherTensor[Plaintext].enc(mpc, [_sum for _ in range((new_size + self.slots - 1) // self.slots)])

        assert not self._transposed, "Ciphertensor: Addition reduction of transposed ciphertensor is not implemented yet"
        return CipherTensor[ctype](
            _data=mpc.he.reduce_add(self._data, min(self.slots, self.shape[-1]), new_size),
            shape=[new_size],
            slots=self.slots)

    def reversed_matmul(self, mpc, other: ndarray, debug=True) -> CipherTensor[ctype]:
        """ Returns other @ self"""
        if self._transposed:
            assert other.shape[1] == self.shape[1], f"CipherTensor: Invalid matrix dimentions for reversed matmul: {other.shape} x {self.shape[::-1]}"
            return CipherTensor[Plaintext].enc(mpc, other).matmul(mpc, self)

        assert self.ndim == other.ndim == 2, f"CipherTensor: At least one of the tensors is not a matrix. Self shape: {self.shape}, other shape: {other.shape}. Ciphertensor matmul supports only matrices at the moment"
        assert other.shape[1] == self.shape[0], f"CipherTensor: Invalid matrix dimentions for reversed matmul: {other.shape} x {self.shape}"

        if isinstance(ctype, Plaintext):
            # TODO: Read dtype (T) from other (add dtype static to CipherTensor class)
            return CipherTensor[Plaintext].enc(mpc, other @ self.decode(mpc, T=float).T)

        new_cipher_tensor = CipherTensor[ctype].zeros(mpc, [other.shape[0], self.shape[1]])

        debug_counter = 1
        for other_column, self_row in zip(other.T, self):
            if debug: print(f"CipherTensor reversed matmul: Computing row {debug_counter}/{self.shape[0]} ...")
            for i, other_elem in enumerate(other_column):
                new_cipher_tensor[i].iadd(mpc, self_row.mul(mpc, other_elem))
            debug_counter += 1
        
        return new_cipher_tensor
    
    def matmul(self, mpc, other, debug=True):
        return self._matmul_v1(mpc, other, debug)
    
    def _matmul_v1(self, mpc, other, debug=True):
        """
        M1 method from https://arxiv.org/pdf/2304.00129.pdf
        """
        if debug: print("Using M1 method for ciphertensor matrix multiplication")
        other_cipher = self._check_other_operand_matmul(mpc, other)
        assert self.ndim == other_cipher.ndim == 2, f"CipherTensor: At least one of the tensors is not a matrix. Self shape: {self.shape}, other shape: {other_cipher.shape}. Ciphertensor matmul supports only matrices at the moment."
        assert self.shape[1] == other_cipher.shape[1], f"CipherTensor: Invalid matrix dimentions for M1 matmul {self.shape} x {other_cipher.shape}"
        assert other_cipher._transposed, "CipherTensor: Ciphertensor should be lazily transposed prior to M1 matrix multiplication by it"

        if isinstance(ctype, Plaintext) and isinstance(other_cipher.ctype, Plaintext):
            # TODO: Read dtype (T) from other (add dtype static to CipherTensor class)
            return CipherTensor[Plaintext].enc(mpc, self.decode(mpc, T=float) @ other.decode(mpc, T=float).T)

        masks = CipherTensor[Plaintext].enc(mpc, [one_hot_vector(i, other_cipher.shape[0], TP=float) for i in range(other_cipher.shape[0])])
        
        new_cipher_tensor = CipherTensor[Ciphertext](
                shape=[0, other_cipher.shape[0]],
                slots=self.slots)
        for i in range(self.shape[0]):
            new_row = CipherTensor[Ciphertext].zeros(mpc, [other_cipher.shape[0]])

            for j in range(other_cipher.shape[0]):
                new_row.iadd(mpc, self[i].mul(mpc, other_cipher[j]).reduce_add(mpc, new_size=other_cipher.shape[0]).mul(mpc, masks[j]))
                if debug: print(f"CipherTensor M1 matmul: {i + 1}/{self.shape[0]} -- {j + 1}/{other_cipher.shape[0]}")
            if debug: print("----------------------")
            
            new_cipher_tensor.append(new_row)
        
        return new_cipher_tensor

    def _matmul_v2(self, mpc, other: CipherTensor, debug=True):
        """
        M2 method from https://arxiv.org/pdf/2304.00129.pdf
        """
        if debug: print("Using M2 method for ciphertensor matrix multiplication")
        assert self.ndim == other.ndim == 2, f"CipherTensor: At least one of the tensors is not a matrix. Self shape: {self.shape}, other shape: {other.shape}. Ciphertensor matmul supports only matrices at the moment."
        assert self.shape[1] == other.shape[0], f"CipherTensor: Invalid matrix dimentions for M2 matmul {self.shape} x {other.shape}"
        assert not other._transposed, "CipherTensor: Ciphertensor should not be lazily transposed prior to M2 matrix multiplication by it"

        if isinstance(ctype, Plaintext) and isinstance(other.ctype, Plaintext):
            # TODO: Read dtype (T) from other (add dtype static to CipherTensor class)
            return CipherTensor[Plaintext].enc(mpc, self.decode(mpc, T=float) @ other.decode(mpc, T=float))

        new_cipher_tensor = CipherTensor[ctype].zeros(mpc, [self.shape[0], other.shape[1]])

        for i in range(self.shape[0]):
            if debug: print(f"CipherTensor M2 matmul: Computing row {i + 1}/{self.shape[0]} ...")
            new_row = new_cipher_tensor[i]
            self_row = self[i]
            for j in range(self.shape[1]):
                other_elem_duplicated = self_row.getitemdup(j)
                new_row.iadd(mpc, other[j].mul(mpc, other_elem_duplicated))
        
        return new_cipher_tensor

    def _handle_plaintext_case(self, mpc, other, op) -> CipherTensor[Plaintext]:
        # TODO: Read dtype on decoding (T) from other (add dtype static to CipherTensor class)
        if not isinstance(other, CipherTensor):
            return CipherTensor[Plaintext].enc(mpc, op(self.decode(mpc, T=float), other))
        elif isinstance(other.ctype, Plaintext):
            return CipherTensor[Plaintext].enc(mpc, op(self.decode(mpc, T=float), other.decode(mpc, T=float)))
        else:
            compile_error("Invalid type for plaintext case elem-wise operand")

    def _check_other_operand_elem_wise(self, mpc, other):
        if isinstance(other, CipherTensor):
            assert not (self._transposed ^ other._transposed), "Ciphertensor: Elem-wise op on transposed ciphertensors is not implemented yet"
            return other
        elif isinstance(other, ndarray):
            operand = other.T if self._transposed else other
            return CipherTensor[Plaintext].enc(mpc, operand.tolist())
        elif isinstance(other, List):
            operand = other.transpose() if self._transposed else other
            return CipherTensor[Plaintext].enc(mpc, operand)
        elif isinstance(other, int) or isinstance(other, float):
            new_tensor_flattened = [other for _ in range(self.shape.reduce_mul())]
            new_cipher = CipherTensor[Plaintext].enc(mpc, new_tensor_flattened)
            new_cipher.shape = self.shape
            new_cipher._transposed = self._transposed
            new_cipher._reset_chunk_size()
            return new_cipher
        else:
            compile_error("Invalid operand for CipherTensor")
    
    def _check_other_operand_matmul(self, mpc, other):
        if isinstance(other, CipherTensor):
            assert other._transposed, "Ciphertensor: Other ciphertensor operand should be transposed on matrix multiplication"
            ct = other
        elif isinstance(other, ndarray):
            ct = CipherTensor[Plaintext].enc(mpc, other.T.tolist())
        elif isinstance(other, List):
            ct = CipherTensor[Plaintext].enc(mpc, other.transpose())
        else:
            compile_error("Invalid operand for CipherTensor")
        
        ct._transposed = True
        return ct

    def _reset_chunk_size(self):
        self._chunk_size = 1 if len(self.shape) <= 1 else CipherTensor._count(self.cipher_shape[1:])


@extend
class ndarray:
    def __matmul__(self, other):
        if isinstance(other, CipherTensor):
            raise NotImplementedError("Cannot multiply by secure value without IR passes enabled.")
            return type(other)()  # To avoid compiler error
        elif isinstance(other, ndarray):
            assert self.shape[1] == other.shape[0] and self.ndim == other.ndim == 2, "ndarray matmul: Invalid shapes"
            
            m, n = self.shape[0], other.shape[1]
            _data = ptr[T](m * n)
            _other_t = other.T

            for i in range(m):
                self_row = self[i]
                start = i * n
                for j in range(n):
                    _data[start + j] = (self_row * _other_t[j]).sum(axis=0)
            
            return ndarray[S, T]._new_contig((m, n), _data)
        else:
            compile_error("Invalid operand for ndarray matmul")
