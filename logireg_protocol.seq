import utils.param as param

from mpc_env import MPCEnv
from utils.type_ops import TypeOps
from utils.utils import \
    get_cache_path, \
    get_output_path, \
    get_temp_path, \
    read_vector_from_cache, \
    read_matrix_from_cache


def neg_log_sigmoid[TP](mpc: MPCEnv[TP], a: list[TP], field: TP) -> tuple[list[TP], list[TP]]:
    n: int = len(a)
    depth: int = 6
    step: float = 4.0
    cur = copy(a)
    a_ind = [TP(0) for _ in range(n)]  # Vector([Zp(0, base=self.primes[fid]) for _ in range(len(a))])

    for i in range(depth):
        cur_sign = mpc.boolean.is_positive(cur)
        index_step = TP(1 << (depth - 1 - i)) % field

        a_ind += (cur_sign * index_step)
        a_ind %= field

        cur_sign *= 2
        if mpc.pid == 1:
            cur_sign -= 1
        cur_sign %= field

        step_fp = TypeOps.double_to_fp(
            step, param.NBIT_K, param.NBIT_F, field)

        cur -= cur_sign * step_fp
        cur %= field

        step //= 2

    if mpc.pid == 1:
        a_ind += 1
    a_ind %= field

    params = mpc.polynomial.table_lookup(a_ind, 2)

    b = mpc.arithmetic.multiply_vec(params[1], a, field)
    b = mpc.fp.trunc_vec(b)

    if mpc.pid > 0:
        b += params[0]

    b_grad = copy(params[1])

    return b, b_grad


def parallel_logistic_regression[TP](
    mpc: MPCEnv[TP], xr: list[list[TP]], xm: list[list[TP]], vr: list[list[TP]],
    vm: list[list[TP]], yr: list[TP], ym: list[TP], max_iter: int) -> tuple[list[TP], list[list[TP]], list[TP]]:
    n: int = vr.shape()[1]
    p: int = vr.shape()[0]
    c: int = xr.shape()[0]
    field: TP = param.BASE_P
    assert vm.shape()[0] == p
    assert vm.shape()[1] == n
    assert xm.shape()[0] == c
    assert xm.shape()[1] == n
    assert xr.shape()[1] == n
    assert len(yr) == n
    assert len(ym) == n

    b0 = [TP(0) for _ in range(c)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(c)])
    bv = [[TP(0) for _ in range(p)] for _ in range(c)]  # Matrix(c, p)
    bx = [TP(0) for _ in range(c)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(c)])

    yneg_r = -yr
    yneg_m = -ym
    if mpc.pid > 0:
        yneg_r += 1
        yneg_r %= field

    yneg = copy(yneg_m)
    if mpc.pid == 1:
        yneg += yneg_r

    fp_memory = TypeOps.double_to_fp(0.5, param.NBIT_K, param.NBIT_F)
    fp_one = TypeOps.double_to_fp(1.0, param.NBIT_K, param.NBIT_F)
    eta: float = 0.3

    step0 = [TP(0) for _ in range(c)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(c)])
    stepv = [[TP(0) for _ in range(p)] for _ in range(c)]  # Matrix(c, p)
    stepx = [TP(0) for _ in range(c)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(c)])

    nbatch: int = 10
    batch_size: int = (n + nbatch - 1) // nbatch

    for it in range(max_iter):
        print(f'Logistic regression iteration {it} initialized')
        batch_index: int = it % nbatch
        start_ind: int = batch_size * batch_index
        end_ind: int = start_ind + batch_size
        if end_ind > n:
            end_ind = n
        cur_bsize: int = end_ind - start_ind

        xr_batch = [[TP(0) for _ in range(cur_bsize)] for _ in range(c)]  # Matrix(c, cur_bsize)
        xm_batch = [[TP(0) for _ in range(cur_bsize)] for _ in range(c)]  # Matrix(c, cur_bsize)
        vr_batch = [[TP(0) for _ in range(cur_bsize)] for _ in range(p)]  # Matrix(p, cur_bsize)
        vm_batch = [[TP(0) for _ in range(cur_bsize)] for _ in range(p)]  # Matrix(p, cur_bsize)
        yn_batch = [TP(0) for _ in range(cur_bsize)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(cur_bsize)])
        ynr_batch = [TP(0) for _ in range(cur_bsize)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(cur_bsize)])
        ynm_batch = [TP(0) for _ in range(cur_bsize)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(cur_bsize)])

        for j in range(c):
            for i in range(cur_bsize):
                xr_batch[j][i] = xr[j][start_ind + i]
                xm_batch[j][i] = xm[j][start_ind + i]

        for j in range(p):
            for i in range(cur_bsize):
                vr_batch[j][i] = vr[j][start_ind + i]
                vm_batch[j][i] = vm[j][start_ind + i]

        for i in range(cur_bsize):
            yn_batch[i] = yneg[start_ind + i]
            ynr_batch[i] = yneg_r[start_ind + i]
            ynm_batch[i] = yneg_m[start_ind + i]

        fp_bsize_inv = TypeOps.double_to_fp(eta * (1.0 / cur_bsize), param.NBIT_K, param.NBIT_F)

        bvr, bvm = mpc.arithmetic.beaver_partition_mat(bv)
        bxr, bxm = mpc.arithmetic.beaver_partition_vec(bx)

        h = mpc.arithmetic.__beaver_matmul(bvr, bvm, vr_batch, vm_batch)
        for j in range(c):
            xrvec = xr_batch[j] * fp_one
            xmvec = xm_batch[j] * fp_one
            h[j] += mpc.arithmetic.__beaver_mult(xrvec, xmvec, bxr[j], bxm[j])
        h = mpc.arithmetic.beaver_reconstruct(h)
        h = mpc.fp.trunc(h, param.NBIT_K + param.NBIT_F, param.NBIT_F)

        for j in range(c):
            h[j] += b0[j]
        h %= field

        hvec = [e for row in h for e in row]  # Matrix().from_value(h).flatten()
        _, s_grad_vec = neg_log_sigmoid[TP](mpc, hvec, field)

        s_grad = [copy(s_grad_vec)]  # Matrix().from_value([TP(0) for _ in range(c)]  # Vector([s_grad_vec], deep_copy=True))
        s_grad = s_grad.reshape([c, cur_bsize])

        d0 = [TP(0) for _ in range(c)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(c)])
        dv = [[TP(0) for _ in range(p)] for _ in range(c)]  # Matrix(c, p)
        dx = [TP(0) for _ in range(c)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(c)])

        for j in range(c):
            s_grad[j] += (yn_batch * fp_one)
            d0[j] = sum(s_grad[j])

        s_grad_r, s_grad_m = mpc.arithmetic.beaver_partition_mat(s_grad)

        for j in range(c):
            dx[j] = mpc.arithmetic.beaver_inner_prod_pair(
                xr_batch[j], xm_batch[j], s_grad_r[j], s_grad_m[j])
        dx = mpc.arithmetic.beaver_reconstruct(dx)

        vr_batch = vr_batch.transpose()
        vm_batch = vm_batch.transpose()
        dv = mpc.arithmetic.__beaver_mult(s_grad_r, s_grad_m, vr_batch, vm_batch)
        dv = mpc.arithmetic.beaver_reconstruct(dv)
        dv = mpc.fp.trunc(dv, param.NBIT_K + param.NBIT_F, param.NBIT_F)

        step0 = step0 * fp_memory - d0 * fp_bsize_inv
        stepv = stepv * fp_memory - dv * fp_bsize_inv
        stepx = stepx * fp_memory - dx * fp_bsize_inv
        step0 %= field
        stepv %= field
        stepx %= field
        step0 = mpc.fp.trunc_vec(step0, param.NBIT_K + param.NBIT_F, param.NBIT_F)
        stepv = mpc.fp.trunc(stepv, param.NBIT_K + param.NBIT_F, param.NBIT_F)
        stepx = mpc.fp.trunc_vec(stepx, param.NBIT_K + param.NBIT_F, param.NBIT_F)

        b0 += step0
        bv += stepv
        bx += stepx

        bv %= field
        bv %= field
        bx %= field

    return b0, bv, bx


def logireg_protocol[TP](mpc: MPCEnv[TP], test_run: bool = True) -> bool:
    # TODO: Implemend threading. (See original implementation of this protocol)
    ntop: int = 100

    n0: int = param.NUM_INDS
    m0: int = param.NUM_SNPS
    k: int = param.NUM_DIM_TO_REMOVE
    field: TP = param.BASE_P

    # Shared variables
    ind: int = 0

    fp_one = TypeOps.double_to_fp(1.0, param.NBIT_K, param.NBIT_F)

    pheno: list[TP] = [TP(0) for _ in range(n0)]  # Vector([Zp(0, param.BASE_P) for _ in range(n0)])
    cov: list[list[TP]] = [[TP(0) for _ in range(param.NUM_COVS)] for _ in range(n0)]  # Matrix(n0, param.NUM_COVS)

    # if not test_run:
    #     if (not os.path.exists(get_cache_path(mpc.pid, 'input_geno')) or
    #         not os.path.exists(get_cache_path(mpc.pid, 'input_pheno_cov'))):
    #         print('Initial data sharing results not found:')
    #         print(f'\t{get_cache_path(mpc.pid, "input_geno")}')
    #         print(f'\t{get_cache_path(mpc.pid, "input_pheno_cov")}')
    #         return False

    print('Initial data sharing results found')

    if not test_run:
        with open(get_cache_path(mpc.pid, 'input_geno'), 'rb') as f:
            pheno = read_vector_from_cache[TP](f, n0, mpc.boolean.primes_bytes[0])
            cov = read_matrix_from_cache[TP](f, n0, param.NUM_COVS, mpc.boolean.primes_bytes[0])
    else:
        with open(get_temp_path(mpc.pid, 'input_pheno_cov')) as f:
            pheno = list[TP](n0)
            cov = list[list[TP]](n0)
            for _ in range(n0):
                pheno.append(TP(next(f)))
            for _ in range(n0):
                cov_row = list[TP](param.NUM_COVS)
                for _ in range(param.NUM_COVS):
                    cov_row.append(TP(next(f)))
                cov.append(cov_row)

    print('Phenotypes and covariates loaded')

    gkeep1 = [TP(0) for _ in range(m0)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(m0)])

    print('Using locus missing rate filter from a previous run')

    if mpc.pid == 2:
        with open(get_output_path(mpc.pid, 'gkeep1')) as f:
            for i, line in zip(range(m0), f):
                gkeep1[i] = TP(line)
        mpc.comms.send(gkeep1, 0)
        mpc.comms.send(gkeep1, 1)
    else:
        gkeep1 = mpc.comms.receive(2, m0)

    m1: int = int(sum(gkeep1))

    ikeep = [TP(0) for _ in range(n0)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(n0)])

    print('Using individual missing rate/het rate filters from a previous run')

    if mpc.pid == 2:
        with open(get_output_path(mpc.pid, 'ikeep')) as f:
            ikeep = [TP(e) for e in f]  # Vector([Zp(int(e), base=param.BASE_P) for e in lines])
        mpc.comms.send(ikeep, 0)
        mpc.comms.send(ikeep, 1)
    else:
        ikeep = mpc.comms.receive(2, n0)

    n1: int = int(sum(ikeep) % field)
    print(f'n1: {n1}, m1: {m1}')

    print('Filtering phenotypes and covariates')
    pheno = [e for i, e in enumerate(pheno) if ikeep[i]]
    cov = [row for i, row in enumerate(cov) if ikeep[i]]

    gkeep2 = [TP(0) for _ in range(m1)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(m1)])

    print('Using MAF/HWE filters from a previous run')

    if mpc.pid == 2:
        with open(get_output_path(mpc.pid, 'gkeep2')) as f:
            for i in range(m1):
                gkeep2[i] = TP(next(f))
        mpc.comms.send(gkeep2, 0)
        mpc.comms.send(gkeep2, 1)
    else:
        gkeep2 = mpc.comms.receive(2, m1)

    m2: int = int(sum(gkeep2) % field)
    print(f'n1: {n1}, m2: {m2}')

    print('Using CA statistics from a previous run')

    gkeep3 = [TP(0) for _ in range(m2)]  # Vector([Zp(0, base=param.BASE_P) for _ in range(m2)])

    if mpc.pid == 2:
        cavec = list[tuple[int, float]](m2)
        with open(get_output_path(mpc.pid, 'assoc')) as f:
            for i, line in zip(range(m2), f):
                val = float(line)
                cavec.append((i, val * val))

        cavec.sort(key=TypeOps.switch_pair[int, float], reverse=True)

        print(f'Selected top {ntop} candidates')
        print(f'Top 5 CA stats: {cavec[:5]}')

        for i in range(ntop):
            gkeep3[cavec[i][0]] = TP(1)

        mpc.comms.send(gkeep3, 0)
        mpc.comms.send(gkeep3, 1)
    else:
        gkeep3 = mpc.comms.receive(2, (m2))

    V: list[list[TP]] = [[TP(0) for _ in range(n1)] for _ in range(k)]  # Matrix(k, n1)

    print('Using eigenvectors from a previous run')
    if not test_run:
        with open(get_cache_path(mpc.pid, 'eigen')) as f:
            V = read_matrix_from_cache[TP](f, k, n1, mpc.boolean.primes_bytes[0])
    else:
        with open(get_temp_path(mpc.pid, 'eigen')) as f:
            V = list[list[TP]](k)
            for _ in range(k):
                V_row = list[TP](n1)
                for _ in range(n1):
                    V_row.append(TP(next(f)))
                V.append(V_row)

    # Concatenate covariate matrix and jointly orthogonalize
    cov = cov.transpose()
    V: list[list[TP]] = V.pad(k + param.NUM_COVS, n1)
    if mpc.pid > 0:
        for i in range(param.NUM_COVS):
            V[k + i] = cov[i] * fp_one
    V %= field

    print('Finding orthonormal basis for ', param.NUM_COVS, n1)
    V: list[list[TP]] = mpc.lin_alg.orthonormal_basis(V)

    V_mean = [TP(0) for _ in range(len(V))]  # Vector([Zp(0, base=param.BASE_P) for _ in range(V.num_rows())])
    fp_denom = TypeOps.double_to_fp(1.0 / len(V[0]), param.NBIT_K, param.NBIT_F)

    for i in range(len(V_mean)):
        V_mean[i] = sum(V[i]) * fp_denom
    V_mean %= field
    V_mean = mpc.fp.trunc_vec(V_mean)
    for i in range(len(V)):
        V[i] -= V_mean
    V %= field

    V_var = mpc.arithmetic.inner_prod(V)
    V_var = mpc.fp.trunc_vec(V_var)
    V_var *= fp_denom
    V_var %= field
    V_var = mpc.fp.trunc_vec(V_var)

    print('Calculating fp_sqrt')
    _, V_stdinv = mpc.fp.fp_sqrt(V_var)

    for i in range(len(V_mean)):
        V[i] = mpc.arithmetic.multiply_vec_scalar(V[i], V_stdinv[i])
    V = mpc.fp.trunc(V, k=param.NBIT_K + param.NBIT_F, m=param.NBIT_F)

    gkeep: list[bool] = [(gkeep1[j] == 1) for j in range(m0)]

    ind: int = 0
    for j in range(m0):
        if gkeep[j]:
            gkeep[j] = (gkeep2[ind] == 1)
            ind += 1

    ind: int = 0
    for j in range(m0):
        if gkeep[j]:
            gkeep[j] = (gkeep3[ind] == 1)
            ind += 1

    # if not os.path.exists(get_cache_path(mpc.pid, 'logi_input')):
    #     raise NotImplementedError(
    #         'At this point, logi_input is expected in cache.\n'
    #         'TODO: Haris. Make it cache agnostic. (See original implementation)')

    X = list[list[TP]](ntop)
    X_mask = list[list[TP]](ntop)
    print('logi_input cache found')
    if not test_run:
        print('Warning! Not implemented: beaver_read_from_file!')
        # with open(get_cache_path(mpc.pid, 'logi_input'), 'br') as f:
        #     X, X_mask = beaver_read_from_file[TP](f, ntop, n1)
    else:
        with open(get_temp_path(mpc.pid, 'logi_input')) as f:
            for _ in range(ntop):
                x_row = list[TP](n1)
                for _ in range(n1):
                    x_row.append(TP(next(f)))
                X.append(x_row)
            for _ in range(ntop):
                x_mask_row = list[TP](n1)
                for _ in range(n1):
                    x_mask_row.append(TP(next(f)))
                X_mask.append(x_mask_row)

    # TODO: Implement data shuffling. (See original implementation)

    V, V_mask = mpc.arithmetic.beaver_partition_mat(V)
    pheno, pheno_mask = mpc.arithmetic.beaver_partition_vec(pheno)

    b = parallel_logistic_regression(mpc, X, X_mask, V, V_mask, pheno, pheno_mask, 1)

    bx = mpc.comms.reveal(b[2])
    if mpc.pid == 2:
        bx_double = TypeOps.fp_to_double_vec(bx, param.NBIT_K, param.NBIT_F)
        output_path: str = get_output_path(mpc.pid, 'logi_coeff')
        # with open(output_path, 'w') as f:
        #     for num in bx_double:
        #         f.write(f'{str(num)}\n')
        print(f'Result written to {output_path}')

    return True
