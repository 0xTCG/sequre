import time
from sequre.utils.param import NBIT_F


def assert_eq(name, result, expected, silent_pass = False):
    assert result == expected, f'{name} failed! Result: {result.__repr__()}.\n\nExpected: {expected.__repr__()}'
    if not silent_pass: print(f'{name} passed.')


def assert_geq(name, result, expected, silent_pass = False):
    assert result >= expected, f'{name} failed! Result: {result.__repr__()}.\n\nExpected to be greater than: {expected.__repr__()}'
    if not silent_pass: print(f'{name} passed.')


def assert_leq(name, result, expected, silent_pass = False):
    assert result <= expected, f'{name} failed! Result: {result.__repr__()}.\n\nExpected to be greater than: {expected.__repr__()}'
    if not silent_pass: print(f'{name} passed.')


def assert_eq_approx(name, result, expected, error: float = 0.018, silent_pass = False):
    # Scale error with the fractional size precision
    error += 1.0 / (2 ** NBIT_F)
    
    check: bool = ((expected - error) < result) and (result < (expected + error))
    assert check, f'{name} failed! Result: {result.__repr__()}.\n\nExpected: {expected.__repr__()}'
    if not silent_pass: print(f'{name} passed.')


def time_frame(mpc, func, name, modulus, *args):
    mpc.reset_stats()
    local_suffix = '_local' if mpc.local else '_online'
    alg_structure = 'Ring' if modulus.popcnt() == 1 else 'Field'

    with open(f'results/{"_".join(name.lower().split())}_stats_CP{mpc.pid}{local_suffix}_on_{alg_structure.lower()}.txt', 'w') as stats_f:
        mpc.reset_stats()
        s = time.time()
        func(mpc, modulus, *args)
        e = time.time()
        
        runtime_message = f'\n{name} done in {e - s}s at CP{mpc.pid}\n'
        stats_f.write(f'{alg_structure} size: {modulus}')
        stats_f.write(runtime_message)
        mpc.print_stats(stats_f)
        print(runtime_message)
        
    mpc.comms.sync_parties()


def score_linear_classificator(predictions, ground_truth):
    positives = [int(e >= 0) for e in predictions]
    pred = [(e * 2 - 1) for e in positives]
    true_positives_count = positives.numpy_eq(ground_truth).sum()
    accuracy = pred.numpy_eq(ground_truth).mean()
    precision = true_positives_count / positives.sum()
    recall = true_positives_count / ([int(e == 1) for e in ground_truth].sum())
    f1 = 2 * (precision * recall) / (precision + recall)
    return accuracy, precision, recall, f1
