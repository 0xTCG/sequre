from bio.fasta import FASTA
from bio.kmer import Kmer
from sequre.types.shared_tensor import SharedTensor as Stensor
from sequre.stdlib.internal import Internal as sq
from sequre.stdlib.builtin import argmax
from sequre.utils.utils import zeros, zeros_vec
from sequre.types.builtin import *
from sequre.attributes import *
import random


def drawfrag(input_fasta, taxid_path, target_coverage, kmer_size=64):
    taxid_infile = open(taxid_path, 'r')

    read_num = 0
    for record in FASTA(input_fasta, fai=False):
        tlabel = int(next(taxid_infile).strip())
        coverage = 0
        desired_coverage = target_coverage * len(record.seq)
        if len(record.seq) >= kmer_size:
            try_num = 0
            while coverage < desired_coverage:
                try_num = try_num + 1
                pos = random.randint(0, len(record.seq) - kmer_size)
                sample = record.seq[pos:pos + kmer_size]
                if not sample.N():
                    coverage = coverage + kmer_size
                    read_num = read_num + 1
                    yield sample, tlabel
                if try_num > 10 * len(record.seq): break


def gen_features(pattern_getters, sequence):
    '''Generates features from a pattern list and a sequence'''
    features = []
    for kmer in sequence.kmers[Kmer[64]](1):
        for i, pat in enumerate(pattern_getters):
            new_seq = str(kmer)[pat]
            features.append(new_seq + str(i))
    return features


def centroid_skms(frag_generator, taxid_path, patterns_path):
    # Read in the pattern file
    patterns = []
    with open(patterns_path, 'r') as pattern_file:
        for pattern in pattern_file:
            patterns.append([int(e) for e in pattern.split()])

    labels = list(int(label.strip()) for label in open(taxid_path, 'r'))
    labels_set = set(labels)
    dico = {v: i for i, v in enumerate(labels_set)}

    all_features = zeros[int](len(labels_set), patterns.shape()[0] * 2)
    features_count = zeros_vec[int](len(labels_set))

    for sequence, label in frag_generator:
        feature_list = gen_features(patterns, sequence)
        feature_list.extend(gen_features(patterns, ~sequence))
        all_features[dico[label]] += [hash(feature) for feature in feature_list]
        features_count[dico[label]] += 1
    
    return all_features // features_count, {v: k for k, v in dico.items()}


def share_data(mpc, input_path, taxid_path, patterns_path, target_coverage, modulus):
    '''
    Can be extended for multiple clients.
    New mean will be sum_i(M_i \cdot c_i) / sum_i(c_i)
    where for i-th client, M_i is the mean and c_i is the count of features per label.
    '''
    frag_generator = drawfrag(input_path, taxid_path, target_coverage)
    centroid_skm, dico = centroid_skms(
        frag_generator=frag_generator,
        taxid_path=taxid_path,
        patterns_path=patterns_path)
    
    return Stensor(mpc.comms.share(centroid_skm.to_int_t(), modulus), modulus), dico


def load_test_features(mpc, input_path, patterns_path, modulus):
    # Read in the pattern file
    patterns = []
    with open(patterns_path, 'r') as pattern_file:
        for pattern in pattern_file:
            patterns.append([int(e) for e in pattern.split()])
    
    all_features = []

    for record in FASTA(input_path, fai=False):
        feature_list = gen_features(patterns, record.seq)
        feature_list.extend(gen_features(patterns, ~record.seq))
        all_features.append([hash(feature) for feature in feature_list])
    
    return Stensor(mpc.comms.share(all_features.to_int_t(), modulus), modulus)


def opal_protocol(mpc, test_run, modulus):
    # TODO: Make the params configurable
    input_path = 'data/opal/A1.train.fasta'
    taxid_path = 'data/opal/A1.train.taxid'
    patterns_path = 'data/opal/patterns.txt'
    test_input_path = 'data/opal/test.fragments.fasta'
    target_coverage = 0.5
    
    # Data sharing should be done apriori in a real-world scenario
    if mpc.pid == 2: print('Sharing data ...')
    bins_centroids, dico = share_data(
        mpc=mpc,
        input_path=input_path,
        taxid_path=taxid_path,
        patterns_path=patterns_path,
        target_coverage=target_coverage,
        modulus=modulus)
    
    # Test features should be shared in apriori in a real-world scenario
    if mpc.pid == 2: print('Loading test features ...')
    test_features = load_test_features(
        mpc=mpc,
        input_path=test_input_path,
        patterns_path=patterns_path,
        modulus=modulus)

    if mpc.pid == 2: print('Calculating predictions ...')
    predictions = Stensor.zeros(len(test_features), modulus=modulus)
    
    for i, test_features_vec in enumerate(test_features):
        if i % 500 == 0: print(f'{i}/{len(test_features)}')
        target_bin_centroids = bins_centroids.zeros()
        for i in range(len(target_bin_centroids)):
            target_bin_centroids[i] = bins_centroids[i] - test_features_vec

        predictions[i] = argmax(mpc, sq.dot(mpc, bins_centroids))
    
    return predictions, dico
