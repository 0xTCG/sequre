from numpy.ndarray import ndarray
from numpy.create import array, zeros_like

from sequre.utils.io import read_matrix
from sequre.utils.stats import score_multi_classificator

from sequre.stdlib.learn.lin_reg import LinReg

from sequre.types.sharetensor import Sharetensor
from sequre.types.multiparty_partition import MPP
from sequre.types.multiparty_union import MPU


def genotype_imputation(mpc, modulus):
    positions = 4779
    sample_size_per_party = 500
    sample_size = (mpc.comms.number_of_parties - 1) * sample_size_per_party
    test_size_per_party = 48
    test_size = (mpc.comms.number_of_parties - 1) * test_size_per_party
    data_size = sample_size + test_size
    
    feature_rank = 31
    weights_len = feature_rank + 1
    output_size = 1
    lin_reg_step_size = 1 / (1 << 13)
    epochs = 100
    optimizer = "mbgd"
    
    accuracies = []
    f_acc = open(f"temp_geno_acc_{epochs}_epochs_{data_size}_{test_size}.txt", "w")
    for pos in range(positions):
        if pos != 2:
            continue
        
        with open(f"/home/hsmajlovic/projects/gtype-imput/data/geno_data_{pos}.txt") as fx, open(f"/home/hsmajlovic/projects/gtype-imput/data/labels_{pos}.txt") as fy:
            raw_X = read_matrix(fx, data_size, feature_rank, False, TP=float)
            raw_y = read_matrix(fy, data_size, output_size, False, TP=float)

        np_X = array(raw_X)
        np_y = array(raw_y)

        training_X = np_X[:sample_size]
        training_y = np_y[:sample_size]
        test_X = np_X[sample_size:]
        test_y = np_y[sample_size:]
        
        # raw_initial_w = ones((weights_len, 1))
        raw_initial_w = ndarray.rand((weights_len, 1))
        
        # Raw data
        X = training_X
        y = training_y
        X_test = test_X
        initial_w = raw_initial_w
        
        # # MPC data
        # X = Sharetensor.enc(mpc, training_X, 0, modulus)
        # y = Sharetensor.enc(mpc, training_y, 0, modulus)
        # X_test = Sharetensor.enc(mpc, test_X, 0, modulus)
        # initial_w = Sharetensor.enc(mpc, raw_initial_w, 0, modulus)
        
        # # MPP data
        # X = MPP(mpc, zeros_like(training_X) if mpc.pid == 0 else training_X[(mpc.pid - 1) * sample_size_per_party:mpc.pid * sample_size_per_party])
        # y = MPP(mpc, zeros_like(training_y) if mpc.pid == 0 else training_y[(mpc.pid - 1) * sample_size_per_party:mpc.pid * sample_size_per_party])
        # X_test = MPP(mpc, zeros_like(test_X) if mpc.pid == 0 else test_X[(mpc.pid - 1) * test_size_per_party:mpc.pid * test_size_per_party])
        # initial_w = MPP(
        #     mpc, zeros_like(raw_initial_w) if mpc.pid == 0 else raw_initial_w[
        #         (mpc.pid - 1) * weights_len // (mpc.comms.number_of_parties - 1):mpc.pid * weights_len // (mpc.comms.number_of_parties - 1)])
        
        # # MPU data
        # X_partition = zeros_like(training_X) if mpc.pid == 0 else training_X[(mpc.pid - 1) * sample_size_per_party:mpc.pid * sample_size_per_party]
        # y_partition = zeros_like(training_y) if mpc.pid == 0 else training_y[(mpc.pid - 1) * sample_size_per_party:mpc.pid * sample_size_per_party]
        # X_test_partition = zeros_like(test_X) if mpc.pid == 0 else test_X[(mpc.pid - 1) * test_size_per_party:mpc.pid * test_size_per_party]
        # X = MPU(mpc, X_partition, "partition")
        # y = MPU(mpc, y_partition, "partition")
        # X_test = MPU(mpc, X_test_partition, "partition")
        # initial_w = MPU(mpc, raw_initial_w if mpc.pid == 1 else zeros_like(raw_initial_w), "aggregate")

        lin_reg = LinReg(initial_w, optimizer).fit(mpc, X=X, y=y, step=lin_reg_step_size, epochs=epochs)
        predictions = lin_reg.predict(mpc, X_test)

        accuracy = score_multi_classificator(predictions.reveal(mpc).flatten().tolist(), test_y.flatten().tolist())
        print(f"CP{mpc.pid}:\t{pos + 1}/{positions} Genotype imputation test accuracy: {accuracy}")
        accuracies.append(accuracy)
        f_acc.write(f"{accuracy}\n")
    
    print(f"CP{mpc.pid}:\tAverage test accuracy: {array(accuracies).mean()}")
    f_acc.close()
