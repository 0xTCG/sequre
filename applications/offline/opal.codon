import time, random

from bio.fasta import FASTA

from sequre.settings import DEBUG
from sequre.stdlib.linear_svm import offline_lsvm_train, offline_lsvm_predict

from ..utils.param import OPAL_COVERAGE, OPAL_TARGET_DICO_LABEL


ACGT = {c: i for i, c in enumerate('ACGT')}


def hmap(feature):
    value = 0
    for c in feature[::-1]: value = (value << 2) | ACGT[c]
    return float(value) / ((1 << (len(feature) * 2)) - 2)


def gen_features(pattern_getters, sequence):
    '''Generates features from a pattern list and a sequence'''
    features = []
    for kmer in sequence.kmers(1, k=64):
        for pat in pattern_getters:
            features.append(str(kmer)[pat])
    return features


def skms(frag_generator, patterns, dico):
    for sequence, label in frag_generator:
        feature_list = gen_features(patterns, sequence)
        feature_list.extend(gen_features(patterns, ~sequence))
        yield dico[label], feature_list


def drawfrag(input_fasta, taxid_path, target_coverage, kmer_size=64):
    taxid_infile = open(taxid_path, 'r')

    for record in FASTA(input_fasta, fai=False):
        tlabel = int(next(taxid_infile).strip())
        coverage = 0
        desired_coverage = target_coverage * len(record.seq)
        if len(record.seq) >= kmer_size:
            try_num = 0
            while coverage < desired_coverage:
                try_num = try_num + 1
                pos = random.randint(0, len(record.seq) - kmer_size)
                sample = record.seq[pos:pos + kmer_size]
                if not sample.N() and len(sample) == kmer_size:
                    coverage = coverage + kmer_size
                    yield sample, tlabel
                if try_num > 10 * len(record.seq): break


def load_dico(taxid_path):
    labels = set(list(int(label.strip()) for label in open(taxid_path, 'r')))
    return {v: i for i, v in enumerate(labels)}, labels


def get_patterns_and_dico(patterns_path, taxid_path):
    patterns = []
    with open(patterns_path, 'r') as pattern_file:
        for pattern in pattern_file:
            patterns.append([int(e) for e in pattern.split()])
    
    dico, labels_set = load_dico(taxid_path)
    return patterns, dico, labels_set


def preprocess_training_data(input_path, taxid_path, patterns_path, target_coverage, target_label):
    s = time.time()
    patterns, dico, _ = get_patterns_and_dico(patterns_path, taxid_path)
    frag_generator = drawfrag(input_path, taxid_path, target_coverage)

    X_positive = []
    y_positive = []
    X_negative = []
    y_negative = []
    count_positives = 0
    count_negatives = 0

    for label, features in skms(frag_generator, patterns, dico):
        if int(label) == target_label:
            count_positives += 1
            X_positive.append(features)
            y_positive.append(1.0)
        else:
            count_negatives += 1
            X_negative.append(features)
            y_negative.append(-1.0)

    if DEBUG:
        assert count_positives > 0
        assert count_negatives > 0
        assert count_negatives > count_positives
    
    neg_data = list(zip(X_negative, y_negative))
    random.shuffle(neg_data)
    neg_data = neg_data[:count_positives]

    data = list(zip(X_positive, y_positive))
    for e in neg_data: data.append(e)
    random.shuffle(data)

    X = []
    y = []
    for features, label in data:
        hashed_features = [hmap(feature) for feature in features]
        X.append(hashed_features)
        y.append(label)
    
    e = time.time()
    print(f'Preprocessing time took {e - s}s')

    return X, y


def preprocess_test_data(input_path, patterns_path):
    # Read in the pattern file
    patterns = []
    with open(patterns_path, 'r') as pattern_file:
        for pattern in pattern_file:
            patterns.append([int(e) for e in pattern.split()])
    
    all_features = []

    for record in FASTA(input_path, fai=False):
        feature_list = gen_features(patterns, record.seq)
        feature_list.extend(gen_features(patterns, ~record.seq))
        hashed_features = [hmap(feature) for feature in feature_list]
        all_features.append(hashed_features)
    
    return all_features


def offline_opal(test_run, coverage = OPAL_COVERAGE, target_label = OPAL_TARGET_DICO_LABEL):
    # TODO: Make the params configurable
    tests_path = 'tests/' if test_run else ''
    input_path = f'{tests_path}data/opal/A1.train.fasta'
    taxid_path = f'{tests_path}data/opal/A1.train.taxid'
    patterns_path = f'{tests_path}data/opal/patterns.txt'
    test_input_path = f'{tests_path}data/opal/test.fragments.fasta'

    print('Preprocessing Opal data ...')
    X, Y = preprocess_training_data(input_path=input_path, taxid_path=taxid_path,
        patterns_path=patterns_path, target_coverage=coverage, target_label=target_label)
    print(f'Training linear SVM ... Input size: {X.shape()}')
    weights, bias = offline_lsvm_train(X=X, Y=Y, eta=0.001, epochs=50, l2=0.001, mini_batch_size=200, optimizer='sgd')

    print('Loading test features ...')
    test_features = preprocess_test_data(test_input_path, patterns_path)
    print(f'Calculating predictions ... Input size: {test_features.shape()}. Weights size: {len(weights)}')
    return offline_lsvm_predict(test_features, weights, bias)
