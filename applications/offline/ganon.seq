import math

from bio.fastq import FASTQ
from bio.fasta import FASTA

from seqan import load_ibf, seqan_ungapped_kmer_encode, _trailing_zeros


class FilterConfig:
    ibf: list[u64]
    ibf_decomposed: list[list[int]]
    map: dict[int, int]
    rel_cutoff: float
    abs_cutoff: float
    bin_count: int
    technical_bin_count: int
    hash_count: int
    hash_shift: int

    def __init__(self, ibf_path, map_path, rel_cutoff, abs_cutoff, bin_count, hash_count):
        self.ibf, self.ibf_decomposed, self.technical_bin_count = load_ibf(ibf_path, bin_count)
        self.map = FilterConfig.load_map(map_path)
        self.rel_cutoff = rel_cutoff
        self.abs_cutoff = abs_cutoff
        self.bin_count = bin_count
        self.hash_count = hash_count
        self.hash_shift = _trailing_zeros(len(self.ibf))

    def load_map(map_path):
        map_dict = {}
        
        with open(map_path) as f:
            for line in f:
                target, count = line.split()
                map_dict[int(count)] = int(target)
        
        return map_dict


class ReadOut:
    read_name: str
    matches: list[tuple[int, int]]

    def __init__(self, read_name):
        self.read_name = read_name
        self.matches = list[tuple[int, int]]()


def threshold_abs(kmers, e, k, o):
    return int(math.ceil(kmers - ( e * k ) / o)) if (kmers * o > e * k) else 0


def threshold_rel(kmers, p):
    return int(math.ceil(kmers * p))


def get_abs_error(kmers, k, o, count):
    return int(math.ceil(o * (-count + kmers) / k))


def select_matches(matches, counts_f, counts_r, filter_map, threshold_cutoff, max_kmer_count_read):
    # for each bin
    # for ( uint32_t bin_n = 0; bin_n < filter.ibf.noOfBins; ++bin_n )
    # loop in map structure to avoid extra validations when map.size() < filter.ibf.noOfBins when ibf is updated and
    # sequences removed also avoid the error of spurius results from empty bins (bug reported)
    for bin_n, target in filter_map.items():
        # if kmer count is higher than threshold_cutoff
        if counts_f[bin_n] >= threshold_cutoff or counts_r[bin_n] >= threshold_cutoff:
            # get best matching strand
            max_kmer_count_bin = max(counts_f[bin_n], counts_r[bin_n])
            # keep only the best match target/read when same targets are split in several bins
            if target not in matches or max_kmer_count_bin > matches[target]:
                # store match to target
                matches[target] = max_kmer_count_bin;
                if max_kmer_count_bin > max_kmer_count_read:
                    max_kmer_count_read = max_kmer_count_bin
    
    return max_kmer_count_read


def get_kmer_encodings(seq, window_size, offset, sigma):
    if window_size > 0:
        # minimizers
        # hashes_f = seqan_ungapped_minimizer_hash(seq, sigma)
        # return hashes_f, hashes_f
        raise NotImplementedError('Offset not implemented')

    if offset > 1:
        # offset
        raise NotImplementedError('Offset not implemented')
    
    # kmer
    return list(seqan_ungapped_kmer_encode(seq, sigma)), list(seqan_ungapped_kmer_encode(~seq, sigma))


def get_threshold_filter(hierarchy_config, kmers, max_kmer_count_read, kmer_size, offset):
    threshold_filter = 0
    if hierarchy_config["rel_filter"] >= 0:
        threshold_filter = max_kmer_count_read - threshold_rel(max_kmer_count_read, hierarchy_config["rel_filter"])
    elif hierarchy_config["abs_filter"] >= 0:
        # get maximum possible number of errors of best match + abs_filter
        max_error_threshold = get_abs_error( kmers, kmer_size, offset, max_kmer_count_read ) + hierarchy_config["abs_filter"]
        # get min kmer count necesary to achieve the calculated number of errors
        threshold_filter = threshold_abs( kmers, max_error_threshold, kmer_size, offset)

    return threshold_filter


def filter_matches(read_name, matches, threshold_filter):
    read_out = ReadOut(read_name)
    
    for target, kmer_count in matches.items():
        if kmer_count >= threshold_filter:
            read_out.matches.append((target, kmer_count))

    return read_out


def output_report(classified_reads, hierarchy_label):
    print(f'Level {hierarchy_label}:')
    
    for read_out in classified_reads:
        print(f'\tMatches for read {read_out.read_name}:')
        for match_tuple in read_out.matches:
            print(f'\t\t{match_tuple}')
    

def __fastq_record_generator(input_fasta):
    for record in FASTA(input_fasta, fai=False):  # FASTQ(input_fasta):
        yield record
